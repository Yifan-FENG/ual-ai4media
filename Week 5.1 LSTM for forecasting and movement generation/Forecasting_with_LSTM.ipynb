{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd989f6b",
   "metadata": {},
   "source": [
    "# Forecasting weather with LSTM\n",
    "\n",
    "In this notebook we are forecasting the temp of future years based on the temp of the past and current year.\n",
    "\n",
    "Based on this source: https://colab.research.google.com/drive/1b3CUJuDOmPmNdZFH3LQDmt5F0K3FZhqD?usp=sharing#scrollTo=1q73lN27SDPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa6da11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5031b8ad",
   "metadata": {},
   "source": [
    "# Using a Tensorflow dataset\n",
    "\n",
    "For this example we are using a Tensorflow dataset. This is optional. You can use your custom numerical datasets instead. \n",
    "\n",
    "Source: https://www.tensorflow.org/tutorials/structured_data/time_series\n",
    "\n",
    "Thorough look into the weather data: https://www.bgc-jena.mpg.de/wetter/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2ab244",
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_path = tf.keras.utils.get_file(\n",
    "        origin='https://storage.googleapis.com/tensorflow/tf-keras-datasets/jena_climate_2009_2016.csv.zip',\n",
    "        fname='jena_climate_2009_2016.csv.zip',\n",
    "        extract=True)\n",
    "csv_path, _ = os.path.splitext(zip_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fd8966",
   "metadata": {},
   "source": [
    "# Reading and printing the data from the csv file\n",
    "\n",
    "As you will see in the next code cell, this weather dataset is composed by 420551 rows Ã— 15 columns.\n",
    "\n",
    "The first column contains the time-related data (date and time) and shows us that we now have access to weather information that were being collected constantly, with 10min intervals (00:10:00, 00:20:00, 00:30:00 and so on), for 8 years (2009 through 2017)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74ef6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df stands for dataframe, which is a two-dimensional data structure,\n",
    "# i.e., data aligned in a tabular fashion in rows and columns\n",
    "df = pd.read_csv(csv_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad8f74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing some information and taking 1h intervals between measurements\n",
    "# Starting from the 5th row (00:00:00) and taking every sixth row after that\n",
    "df = df[5::6]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd73b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the first column as our index number\n",
    "df.index = pd.to_datetime(df['Date Time'], format='%d.%m.%Y %H:%M:%S')\n",
    "df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c63623a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting and printing the recurrent pattern of temperatures through the years/months/days\n",
    "temp = df['T (degC)']\n",
    "temp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493d7840",
   "metadata": {},
   "source": [
    "# Forecasting as a supervised learning problem\n",
    "\n",
    "This is where things get interesting. At this step, we define the number of sequential data that define the value of the next one. \n",
    "\n",
    "In our case, we will use a window size of 5, which means that every 5 dataframes, we make a prediction for the next one. Then, the predicted one becomes part of the next batch of 5 and the predicted one becomes part of the next batch of 5, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d9aa89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Every 5 hours predict the temp for the next hour:\n",
    "# ---------------------------------------------------------------\n",
    "#  X matrix                       y vector (correponsing output)\n",
    "# ---------------------------------------------------------------\n",
    "# [[[1], [2], [3], [4], [5]]]    [6]\n",
    "# [[[2], [3], [4], [5], [6]]]    [7]\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "def df_to_X_y(df, window_size):\n",
    "    df_as_np = df.to_numpy()\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(df_as_np)-window_size):\n",
    "        row = [[a] for a in df_as_np[i:i+window_size]]\n",
    "        X.append(row)\n",
    "        label = df_as_np[i+window_size]\n",
    "        y.append(label)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80dbb1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X holds all the batches of 5 for all dataframes\n",
    "# y holds all the dataframe values that follow every batch of 5\n",
    "WINDOW_SIZE = 5\n",
    "X, y = df_to_X_y(temp, WINDOW_SIZE)\n",
    "X.shape, y.shape\n",
    "#print(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1988ea50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spliting dataset in training, validation and testing datasets\n",
    "X_train, y_train = X[:60000], y[:60000]\n",
    "X_val, y_val = X[60000:65000], y[60000:65000]\n",
    "X_test, y_test = X[65000:], y[65000:]\n",
    "X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf36ec2",
   "metadata": {},
   "source": [
    "# Building our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb515f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries for our model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import InputLayer\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb85c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incorporating an LSTM model with 64 units\n",
    "# The output is just one number, one prediction\n",
    "model = Sequential()\n",
    "model.add(InputLayer((5,1)))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dense(8, 'relu'))\n",
    "model.add(Dense(1, 'linear'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379bfb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving only the one that has the lowest validation loss\n",
    "cp = ModelCheckpoint('model/', save_best_only=True)\n",
    "model.compile(loss=MeanSquaredError(), optimizer=Adam(learning_rate=0.0001), metrics=[RootMeanSquaredError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adbff38",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=2, callbacks=[cp]) #10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0f5184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading our model\n",
    "model = load_model('model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03f7ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making some predictions with our training data\n",
    "# Comparing our predictions with the actual data\n",
    "train_predictions = model.predict(X_train).flatten()\n",
    "train_results = pd.DataFrame(data={'Train Predictions':train_predictions, 'Actuals':y_train})\n",
    "train_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702dfc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seeing the difference between them in a graph\n",
    "plt.plot(train_results['Train Predictions'][:100], 'b-')\n",
    "plt.plot(train_results['Actuals'][:100], 'r-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b325ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making some predictions with our validation data\n",
    "# Comparing our predictions with the actual data\n",
    "val_predictions = model.predict(X_val).flatten()\n",
    "val_results = pd.DataFrame(data={'Val Predictions':val_predictions, 'Actuals':y_val})\n",
    "val_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51014ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seeing the difference between them in a graph\n",
    "plt.plot(val_results['Val Predictions'][:100], 'b-')\n",
    "plt.plot(val_results['Actuals'][:100], 'r-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303e331c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making some predictions with our testing data\n",
    "# Comparing our predictions with the actual data\n",
    "test_predictions = model.predict(X_test).flatten()\n",
    "test_results = pd.DataFrame(data={'Test Predictions':test_predictions, 'Actuals':y_test})\n",
    "test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc37c41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seeing the difference between them in a graph\n",
    "plt.plot(test_results['Test Predictions'][:100], 'b-')\n",
    "plt.plot(test_results['Actuals'][:100], 'r-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822afd03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
