{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUQYSs-OH0xj"
      },
      "source": [
        "# Image classification from scratch\n",
        "\n",
        "In this notebook we are going to train a CNN image classifier from scratch on a custom dataset. We will be working with a simple CNN architecture, similiar to the LeNet architecture discussed in the lecture. \n",
        "\n",
        "We will be working with quite small images in this notebook as training a CNN from scratch can take a very long time when working with larger images and bigger CNN models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBygfyY9H0xl"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mvM5TJXOH0xl"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import datasets, layers, models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70fwLDjTH0xn"
      },
      "source": [
        "## Load your dataset\n",
        "\n",
        "To train a classification model, we need a dataset of images where different categories of images are organised into classes. This is as simple as putting images of different things into different folder.\n",
        "i.e:\n",
        "```\n",
        "my_dataset/clouds/cloud_0001.jpg\n",
        "my_dataset/clouds/cloud_0002.jpg\n",
        "..\n",
        "my_dataset/candy_floss/cfloss_0001.jpg\n",
        "my_dataset/candy_floss/cfloss_0002.jpg\n",
        "```\n",
        "\n",
        "There are plenty of classification datasets on the internet but it's more fun and more of a challenge to train a classifier on a dataset that we have made ourselves. Why don't you take the image dataset you made in the last session and use that! You may need to add an extra category for classification if you only had one category images previously. You can refer back to [last weeks instructions](https://moodle.arts.ac.uk/mod/page/view.php?id=954147) if you get stuck. All you need to do is put some new images in a different folder, and then put both those folders into a folder for the whole dataset. You don't need to worry about resizing all the images for this task as keras will take care of image resizing for us.\n",
        "\n",
        "Once you have got your dataset, change the path in the `dataset_path` variable to the path to your dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3AV2pePvH0xn"
      },
      "outputs": [],
      "source": [
        "image_size = (64, 64)\n",
        "batch_size = 128\n",
        "num_classes = 2\n",
        "dataset_path = 'path/to/dataset'\n",
        "\n",
        "train = tf.keras.utils.image_dataset_from_directory(\n",
        "    dataset_path,\n",
        "    validation_split=0.2,\n",
        "    subset='training',\n",
        "    seed=1,\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size,\n",
        ")\n",
        "\n",
        "validation = tf.keras.utils.image_dataset_from_directory(\n",
        "    dataset_path,\n",
        "    validation_split=0.2,\n",
        "    subset='validation',\n",
        "    seed=1,\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2NcN4TUH0xn"
      },
      "source": [
        "## Visualize the data\n",
        "\n",
        "Here are the first 9 images in the training dataset. As you can see, label 1 is \"dog\"\n",
        "and label 0 is \"cat\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rOfxqZi7H0xo"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train.take(1):\n",
        "    for i in range(9):\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "        plt.title(int(labels[i]))\n",
        "        plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIwZz8HFH0xp"
      },
      "source": [
        "## Build a model\n",
        "\n",
        "We'll build a small version of the Xception network. We haven't particularly tried to\n",
        "optimize the architecture; if you want to do a systematic search for the best model\n",
        "configuration, consider using\n",
        "[KerasTuner](https://github.com/keras-team/keras-tuner).\n",
        "\n",
        "Note that:\n",
        "\n",
        "- We start the model with the `data_augmentation` preprocessor, followed by a\n",
        " `Rescaling` layer.\n",
        "- We include a `Dropout` layer before the final classification layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qCh6vf1EH0xp"
      },
      "outputs": [],
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(image_size[0], image_size[1], 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "if num_classes == 2:\n",
        "    model.add(layers.Dense(1))\n",
        "else:\n",
        "    model.add(layers.Dense(num_classes))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTEBpe4lH0xp"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pBwLBANaH0xp"
      },
      "outputs": [],
      "source": [
        "epochs = 10\n",
        "if num_classes == 2:\n",
        "    loss_function = \"binary_crossentropy\"\n",
        "else:\n",
        "    loss_function = \"categorical_crossentropy\"\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(1e-3),\n",
        "    loss=loss_function,\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "model.fit(\n",
        "    train,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Optional: save the model\n",
        "This is how we save the weights of the model for savekeeping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save('classifer_from_scratch.model')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Next steps\n",
        "Now go onto the notebook transfer learning for image classification and try training a model on the same data using transfer learning to compare the results.\n",
        "\n",
        "### Bonus exercise\n",
        "Look at the [reference for the Conv2D layer in tensorflow](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D), see if you can modify the network code in this notebook to make use of strided convolutions for downsampling rather than using Max-pooling layers."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "image_classification_from_scratch",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.9.15 ('aim_week3')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "vscode": {
      "interpreter": {
        "hash": "b7f6b83f8c63488afc271070561874a11a039d471dfbe07d7ca18d88af4be80a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
